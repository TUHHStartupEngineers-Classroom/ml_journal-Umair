<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />



<meta name="date" content="2020-01-06" />

<title>03 Automated Machine Learning with H20</title>

<script src="site_libs/header-attrs-2.8/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MyLabJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Index</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Journal
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_ml_fund.html">01 Machine Learning Fundamentals</a>
    </li>
    <li>
      <a href="02_ml_sup.html">02 Supervised ML</a>
    </li>
    <li>
      <a href="03_ml_aut.html">03 Automated Machine Learning with H20</a>
    </li>
    <li>
      <a href="04_perf_meas.html">04 Performance Measures</a>
    </li>
    <li>
      <a href="05_lime.html">05 LIME</a>
    </li>
    <li>
      <a href="06_dl.html">06 Deep Learning</a>
    </li>
  </ul>
</li>
<li>
  <a href="07_class_notes.html">Class notes</a>
</li>
<li>
  <a href="08_links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">03 Automated Machine Learning with H20</h1>
<h4 class="date">2020-01-06</h4>

</div>


<p><strong>IMPORTANT:</strong> You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.</p>
<p>This is an <code>.Rmd</code> file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.</p>
<div id="my-first-post" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> My first post</h1>
<p>Last compiled: 2021-06-03</p>
<p>Notice that whatever you define as a top level header, automatically gets put into the table of contents bar on the left.</p>
<div id="second-level-header" class="section level2" number="1.1">
<h2 number="1.1"><span class="header-section-number">1.1</span> Second level header</h2>
<p>You can add more headers by adding more hashtags. These won’t be put into the table of contents</p>
<div id="third-level-header" class="section level3" number="1.1.1">
<h3 number="1.1.1"><span class="header-section-number">1.1.1</span> third level header</h3>
<p>Here’s an even lower level header</p>
</div>
</div>
</div>
<div id="my-second-post-note-the-order" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> My second post (note the order)</h1>
<p>Last compiled: 2021-06-03</p>
<p>I’m writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom</p>
</div>
<div id="adding-r-stuff" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Adding R stuff</h1>
<p>So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the same place.</p>
<p>So, let’s say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation = 1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:</p>
<pre class="r"><code>library(tidyverse)
library(readxl)
library(h2o)
library(rsample)
library(recipes)





############ STEP # 1 ############################




product_backorder_tbl          &lt;- read_csv(&quot;product_backorders.csv&quot;)

set.seed(seed = 1113)
split_obj                       &lt;- rsample::initial_split(product_backorder_tbl, prop = 0.85)
train_readable_tbl              &lt;- training(split_obj)
test_readable_tbl               &lt;- testing(split_obj)

recipe_obj &lt;- recipe(went_on_backorder ~., data = train_readable_tbl) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  prep()

train_tbl &lt;- bake(recipe_obj, new_data = train_readable_tbl)
test_tbl  &lt;- bake(recipe_obj, new_data = test_readable_tbl)















############ STEP # 2 ############################




# Modeling
h2o.init()</code></pre>
<pre><code>##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         4 days 6 hours 
##     H2O cluster timezone:       +01:00 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.32.1.3 
##     H2O cluster version age:    15 days  
##     H2O cluster name:           H2O_started_from_R_M_Umair_Chaudhry_wae888 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   0.96 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4 
##     R Version:                  R version 4.1.0 (2021-05-18)</code></pre>
<pre class="r"><code>split_h2o &lt;- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>train_h2o &lt;- split_h2o[[1]]
valid_h2o &lt;- split_h2o[[2]]
test_h2o  &lt;- as.h2o(test_tbl)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>y &lt;- &quot;went_on_backorder&quot;
x &lt;- setdiff(names(train_h2o), y)






############ STEP # 3 ############################




#?h2o.automl

automl_models_h2o &lt;- h2o.automl(
  x = x,
  y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = 300,
  nfolds            = 5 
)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
## 18:58:40.666: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.
## 18:58:40.690: AutoML: XGBoost is not available; skipping it.
  |                                                                            
  |===                                                                   |   4%
  |                                                                            
  |===                                                                   |   5%
  |                                                                            
  |=====                                                                 |   7%
  |                                                                            
  |=====                                                                 |   8%
  |                                                                            
  |======                                                                |   9%
  |                                                                            
  |========================                                              |  34%
  |                                                                            
  |========================                                              |  35%
  |                                                                            
  |=========================                                             |  36%
  |                                                                            
  |==========================                                            |  38%
  |                                                                            
  |===========================                                           |  38%
  |                                                                            
  |============================                                          |  40%
  |                                                                            
  |=============================                                         |  41%
  |                                                                            
  |=============================                                         |  42%
  |                                                                            
  |===============================                                       |  44%
  |                                                                            
  |================================                                      |  46%
  |                                                                            
  |=================================                                     |  47%
  |                                                                            
  |==================================                                    |  48%
  |                                                                            
  |===================================                                   |  50%
  |                                                                            
  |====================================                                  |  52%
  |                                                                            
  |=====================================                                 |  53%
  |                                                                            
  |=======================================                               |  56%
  |                                                                            
  |========================================                              |  57%
  |                                                                            
  |=========================================                             |  58%
  |                                                                            
  |===========================================                           |  61%
  |                                                                            
  |============================================                          |  62%
  |                                                                            
  |============================================                          |  63%
  |                                                                            
  |===============================================                       |  67%
  |                                                                            
  |================================================                      |  68%
  |                                                                            
  |================================================                      |  69%
  |                                                                            
  |=================================================                     |  69%
  |                                                                            
  |==================================================                    |  71%
  |                                                                            
  |==================================================                    |  72%
  |                                                                            
  |===================================================                   |  73%
  |                                                                            
  |=======================================================               |  78%
  |                                                                            
  |==========================================================            |  82%
  |                                                                            
  |============================================================          |  85%
  |                                                                            
  |===============================================================       |  89%
  |                                                                            
  |===================================================================   |  95%
  |                                                                            
  |====================================================================  |  97%
  |                                                                            
  |===================================================================== |  99%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>################Step 4 View the leaderboard##############


typeof(automl_models_h2o)</code></pre>
<pre><code>## [1] &quot;S4&quot;</code></pre>
<pre class="r"><code>slotNames(automl_models_h2o)</code></pre>
<pre><code>## [1] &quot;project_name&quot;   &quot;leader&quot;         &quot;leaderboard&quot;    &quot;event_log&quot;     
## [5] &quot;modeling_steps&quot; &quot;training_info&quot;</code></pre>
<pre class="r"><code>automl_models_h2o@leaderboard</code></pre>
<pre><code>##                                              model_id       auc   logloss
## 1    StackedEnsemble_AllModels_AutoML_20210603_185840 0.9486342 0.1769285
## 2                        GBM_3_AutoML_20210603_185840 0.9473321 0.1936662
## 3 StackedEnsemble_BestOfFamily_AutoML_20210603_185840 0.9460521 0.1800126
## 4                        GBM_2_AutoML_20210603_185840 0.9457914 0.1893308
## 5          GBM_grid__1_AutoML_20210603_185840_model_2 0.9445998 0.1843899
## 6          GBM_grid__1_AutoML_20210603_185840_model_1 0.9426618 0.1863229
##       aucpr mean_per_class_error      rmse        mse
## 1 0.7392267            0.1369320 0.2299968 0.05289854
## 2 0.7275842            0.1523850 0.2376149 0.05646082
## 3 0.7281310            0.1589795 0.2316103 0.05364333
## 4 0.7239801            0.1460507 0.2351668 0.05530343
## 5 0.7189022            0.1562101 0.2347458 0.05510557
## 6 0.7326728            0.1729790 0.2350094 0.05522941
## 
## [21 rows x 7 columns]</code></pre>
<pre class="r"><code>automl_models_h2o@leader</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: stackedensemble
## Model ID:  StackedEnsemble_AllModels_AutoML_20210603_185840 
## Number of Base Models: 19
## 
## Base Models (count by algorithm type):
## 
## deeplearning          drf          gbm          glm 
##            6            2           10            1 
## 
## Metalearner:
## 
## Metalearner algorithm: glm
## Metalearner cross-validation fold assignment:
##   Fold assignment scheme: AUTO
##   Number of folds: 5
##   Fold column: NULL
## Metalearner hyperparameters: 
## 
## 
## H2OBinomialMetrics: stackedensemble
## ** Reported on training data. **
## 
## MSE:  0.021994
## RMSE:  0.1483037
## LogLoss:  0.08672016
## Mean Per-Class Error:  0.06713245
## AUC:  0.9926497
## AUCPR:  0.9589412
## Gini:  0.9852993
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     8771  116 0.013053   =116/8887
## Yes     144 1044 0.121212   =144/1188
## Totals 8915 1160 0.025806  =260/10075
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.447227    0.889267 169
## 2                       max f2  0.253738    0.904341 225
## 3                 max f0point5  0.628668    0.919529 124
## 4                 max accuracy  0.471477    0.974392 164
## 5                max precision  0.998992    1.000000   0
## 6                   max recall  0.027261    1.000000 343
## 7              max specificity  0.998992    1.000000   0
## 8             max absolute_mcc  0.471477    0.874943 164
## 9   max min_per_class_accuracy  0.222825    0.953640 235
## 10 max mean_per_class_accuracy  0.245994    0.954606 227
## 11                     max tns  0.998992 8887.000000   0
## 12                     max fns  0.998992 1182.000000   0
## 13                     max fps  0.000163 8887.000000 399
## 14                     max tps  0.027261 1188.000000 343
## 15                     max tnr  0.998992    1.000000   0
## 16                     max fnr  0.998992    0.994949   0
## 17                     max fpr  0.000163    1.000000 399
## 18                     max tpr  0.027261    1.000000 343
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: stackedensemble
## ** Reported on validation data. **
## 
## MSE:  0.04882418
## RMSE:  0.2209619
## LogLoss:  0.1643854
## Mean Per-Class Error:  0.1277245
## AUC:  0.9552738
## AUCPR:  0.7734796
## Gini:  0.9105476
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     1974 130 0.061787  =130/2104
## Yes      55 229 0.193662    =55/284
## Totals 2029 359 0.077471  =185/2388
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.233186    0.712286 204
## 2                       max f2  0.125562    0.789149 251
## 3                 max f0point5  0.711187    0.758929  85
## 4                 max accuracy  0.525438    0.933836 129
## 5                max precision  0.984552    1.000000   0
## 6                   max recall  0.002118    1.000000 394
## 7              max specificity  0.984552    1.000000   0
## 8             max absolute_mcc  0.233186    0.674354 204
## 9   max min_per_class_accuracy  0.127156    0.891160 250
## 10 max mean_per_class_accuracy  0.105138    0.896910 263
## 11                     max tns  0.984552 2104.000000   0
## 12                     max fns  0.984552  282.000000   0
## 13                     max fps  0.000176 2104.000000 399
## 14                     max tps  0.002118  284.000000 394
## 15                     max tnr  0.984552    1.000000   0
## 16                     max fnr  0.984552    0.992958   0
## 17                     max fpr  0.000176    1.000000 399
## 18                     max tpr  0.002118    1.000000 394
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: stackedensemble
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05097376
## RMSE:  0.2257737
## LogLoss:  0.1720897
## Mean Per-Class Error:  0.1552296
## AUC:  0.9517844
## AUCPR:  0.737143
## Gini:  0.9035687
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error         Rate
## No     11593  576 0.047333   =576/12169
## Yes      431 1207 0.263126    =431/1638
## Totals 12024 1783 0.072934  =1007/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.340801     0.705642 201
## 2                       max f2  0.124320     0.775081 285
## 3                 max f0point5  0.646597     0.729921 113
## 4                 max accuracy  0.485334     0.931049 160
## 5                max precision  0.996726     1.000000   0
## 6                   max recall  0.000290     1.000000 399
## 7              max specificity  0.996726     1.000000   0
## 8             max absolute_mcc  0.340801     0.664881 201
## 9   max min_per_class_accuracy  0.111501     0.885836 292
## 10 max mean_per_class_accuracy  0.109184     0.887027 293
## 11                     max tns  0.996726 12169.000000   0
## 12                     max fns  0.996726  1637.000000   0
## 13                     max fps  0.000290 12169.000000 399
## 14                     max tps  0.000290  1638.000000 399
## 15                     max tnr  0.996726     1.000000   0
## 16                     max fnr  0.996726     0.999389   0
## 17                     max fpr  0.000290     1.000000 399
## 18                     max tpr  0.000290     1.000000 399
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre>
<pre class="r"><code>extract_h2o_model_name_by_position &lt;- function(h2o_leaderboard, n = 1, verbose = T) {
  
  model_name &lt;- h2o_leaderboard %&gt;%
    as_tibble() %&gt;%
    slice(n) %&gt;%
    pull(model_id)
  
  if (verbose) message(model_name)
  
  return(model_name)
  
}


automl_models_h2o@leaderboard %&gt;% 
  extract_h2o_model_name_by_position(14) %&gt;% 
  h2o.getModel() %&gt;%






################ Saving &amp; Loading H2O models Step#5 ###############


  h2o.saveModel(path = &quot;04_Modeling/h20_models/challenge&quot;)</code></pre>
<pre><code>## [1] &quot;C:\\THIS PC\\TUHH S-I\\S - IV\\ML\\Challenge\\Challange_H2O\\Challenge_H2O_2\\Challenge\\Challenge_2nd_Actual\\04_Modeling\\h20_models\\challenge\\GBM_grid__1_AutoML_20210603_185840_model_5&quot;</code></pre>
<pre class="r"><code>h2o.loadModel(&quot;04_Modeling/h20_models/challenge/GBM_grid__1_AutoML_20210531_150000_model_3&quot;)</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: gbm
## Model ID:  GBM_grid__1_AutoML_20210531_150000_model_3 
## Model Summary: 
##   number_of_trees number_of_internal_trees model_size_in_bytes min_depth
## 1              68                       68              283064         0
##   max_depth mean_depth min_leaves max_leaves mean_leaves
## 1        12   11.26471          1        680   326.50000
## 
## 
## H2OBinomialMetrics: gbm
## ** Reported on training data. **
## 
## MSE:  0.01361432
## RMSE:  0.1166804
## LogLoss:  0.06477669
## Mean Per-Class Error:  0.02881662
## AUC:  0.9982883
## AUCPR:  0.9907718
## Gini:  0.9965767
## R^2:  0.8697956
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error        Rate
## No     12114   55 0.004520   =55/12169
## Yes       87 1551 0.053114    =87/1638
## Totals 12201 1606 0.010285  =142/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.409278     0.956227 185
## 2                       max f2  0.320421     0.960746 205
## 3                 max f0point5  0.554375     0.969592 154
## 4                 max accuracy  0.409278     0.989715 185
## 5                max precision  0.986446     1.000000   0
## 6                   max recall  0.032997     1.000000 337
## 7              max specificity  0.986446     1.000000   0
## 8             max absolute_mcc  0.409278     0.950460 185
## 9   max min_per_class_accuracy  0.239557     0.979853 228
## 10 max mean_per_class_accuracy  0.212380     0.980571 239
## 11                     max tns  0.986446 12169.000000   0
## 12                     max fns  0.986446  1635.000000   0
## 13                     max fps  0.000993 12169.000000 399
## 14                     max tps  0.032997  1638.000000 337
## 15                     max tnr  0.986446     1.000000   0
## 16                     max fnr  0.986446     0.998168   0
## 17                     max fpr  0.000993     1.000000 399
## 18                     max tpr  0.032997     1.000000 337
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: gbm
## ** Reported on validation data. **
## 
## MSE:  0.0500568
## RMSE:  0.2237338
## LogLoss:  0.1676649
## Mean Per-Class Error:  0.1296357
## AUC:  0.9554897
## AUCPR:  0.7650123
## Gini:  0.9109794
## R^2:  0.5222864
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2003 101 0.048004  =101/2104
## Yes      60 224 0.211268    =60/284
## Totals 2063 325 0.067420  =161/2388
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.231980    0.735632 202
## 2                       max f2  0.112987    0.787822 256
## 3                 max f0point5  0.509848    0.751916 123
## 4                 max accuracy  0.315646    0.937605 176
## 5                max precision  0.971834    1.000000   0
## 6                   max recall  0.003773    1.000000 389
## 7              max specificity  0.971834    1.000000   0
## 8             max absolute_mcc  0.231980    0.699278 202
## 9   max min_per_class_accuracy  0.096959    0.891160 267
## 10 max mean_per_class_accuracy  0.084637    0.895528 275
## 11                     max tns  0.971834 2104.000000   0
## 12                     max fns  0.971834  283.000000   0
## 13                     max fps  0.001067 2104.000000 399
## 14                     max tps  0.003773  284.000000 389
## 15                     max tnr  0.971834    1.000000   0
## 16                     max fnr  0.971834    0.996479   0
## 17                     max fpr  0.001067    1.000000 399
## 18                     max tpr  0.003773    1.000000 389
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: gbm
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05264287
## RMSE:  0.2294403
## LogLoss:  0.1755659
## Mean Per-Class Error:  0.1362506
## AUC:  0.9506946
## AUCPR:  0.7351852
## Gini:  0.9013892
## R^2:  0.4965349
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error         Rate
## No     11416  753 0.061879   =753/12169
## Yes      345 1293 0.210623    =345/1638
## Totals 11761 2046 0.079525  =1098/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.194276     0.701954 245
## 2                       max f2  0.121130     0.779974 277
## 3                 max f0point5  0.537980     0.723443 136
## 4                 max accuracy  0.457335     0.929746 160
## 5                max precision  0.987549     1.000000   0
## 6                   max recall  0.002288     1.000000 395
## 7              max specificity  0.987549     1.000000   0
## 8             max absolute_mcc  0.194276     0.662128 245
## 9   max min_per_class_accuracy  0.091993     0.887337 292
## 10 max mean_per_class_accuracy  0.088803     0.888101 294
## 11                     max tns  0.987549 12169.000000   0
## 12                     max fns  0.987549  1636.000000   0
## 13                     max fps  0.000742 12169.000000 399
## 14                     max tps  0.002288  1638.000000 395
## 15                     max tnr  0.987549     1.000000   0
## 16                     max fnr  0.987549     0.998779   0
## 17                     max fpr  0.000742     1.000000 399
## 18                     max tpr  0.002288     1.000000 395
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                               mean           sd  cv_1_valid cv_2_valid
## accuracy                0.92634124 0.0058955573   0.9301231   0.929399
## auc                     0.95055467 0.0053486945   0.9596708  0.9498743
## err                     0.07365879 0.0058955573   0.0698769 0.07060102
## err_count                    203.4    16.257305       193.0      195.0
## f0point5                0.68391705   0.02991979  0.72422683  0.6791641
## f1                       0.7059194  0.025415042   0.7443709  0.6938776
## f2                       0.7297664  0.025698777  0.76566756 0.70924264
## lift_top_group            7.292422   0.57823396   7.1242065  7.7114935
## logloss                 0.17556679  0.006108442   0.1722436 0.16717628
## max_per_class_error      0.2531705  0.029838206  0.21944444  0.2801303
## mcc                     0.66556454  0.026862245   0.7050183 0.65457976
## mean_per_class_accuracy  0.8485961   0.01391779   0.8665475 0.83773524
## mean_per_class_error    0.15140389   0.01391779  0.13345245 0.16226473
## mse                     0.05264312 0.0024623007 0.051882558 0.04987479
## pr_auc                  0.73401904  0.035947163   0.7964472 0.72957194
## precision                0.6701556  0.033995394   0.7113924   0.669697
## r2                      0.49547786    0.0311478    0.542287  0.4951777
## recall                   0.7468295  0.029838206  0.78055555 0.71986973
## rmse                    0.22939128  0.005334302  0.22777744 0.22332664
## specificity              0.9503627 0.0074749193  0.95253956  0.9556008
##                          cv_3_valid  cv_4_valid  cv_5_valid
## accuracy                  0.9159725   0.9290112   0.9272003
## auc                      0.94963557   0.9458547  0.94773793
## err                      0.08402753 0.070988774  0.07279971
## err_count                     232.0       196.0       201.0
## f0point5                 0.64035547   0.6892718   0.6865672
## f1                       0.67867035    0.716763   0.6959153
## f2                       0.72186214   0.7465382  0.70552146
## lift_top_group            7.8885713   7.3268466   6.4109907
## logloss                  0.18324228  0.17697719  0.17819464
## max_per_class_error      0.24615385  0.23219815   0.2879257
## mcc                       0.6350696  0.67834747   0.6548075
## mean_per_class_accuracy   0.8457244   0.8590855   0.8338879
## mean_per_class_error     0.15427561   0.1409145  0.16611215
## mse                     0.056447804 0.051640376 0.053370077
## pr_auc                   0.71895355   0.7197691   0.7053535
## precision                 0.6171285   0.6720867   0.6804734
## r2                       0.45647538  0.50009674   0.4833524
## recall                   0.75384617   0.7678019   0.7120743
## rmse                     0.23758747  0.22724518  0.23101965
## specificity              0.93760264   0.9503692   0.9557014</code></pre>
<pre class="r"><code>############### Step 5 Predicting using Leader Model#####################


stacked_ensemble_h2o &lt;- h2o.loadModel(&quot;04_Modeling/h20_models/challenge/GBM_grid__1_AutoML_20210531_150000_model_3&quot;)
stacked_ensemble_h2o</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: gbm
## Model ID:  GBM_grid__1_AutoML_20210531_150000_model_3 
## Model Summary: 
##   number_of_trees number_of_internal_trees model_size_in_bytes min_depth
## 1              68                       68              283064         0
##   max_depth mean_depth min_leaves max_leaves mean_leaves
## 1        12   11.26471          1        680   326.50000
## 
## 
## H2OBinomialMetrics: gbm
## ** Reported on training data. **
## 
## MSE:  0.01361432
## RMSE:  0.1166804
## LogLoss:  0.06477669
## Mean Per-Class Error:  0.02881662
## AUC:  0.9982883
## AUCPR:  0.9907718
## Gini:  0.9965767
## R^2:  0.8697956
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error        Rate
## No     12114   55 0.004520   =55/12169
## Yes       87 1551 0.053114    =87/1638
## Totals 12201 1606 0.010285  =142/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.409278     0.956227 185
## 2                       max f2  0.320421     0.960746 205
## 3                 max f0point5  0.554375     0.969592 154
## 4                 max accuracy  0.409278     0.989715 185
## 5                max precision  0.986446     1.000000   0
## 6                   max recall  0.032997     1.000000 337
## 7              max specificity  0.986446     1.000000   0
## 8             max absolute_mcc  0.409278     0.950460 185
## 9   max min_per_class_accuracy  0.239557     0.979853 228
## 10 max mean_per_class_accuracy  0.212380     0.980571 239
## 11                     max tns  0.986446 12169.000000   0
## 12                     max fns  0.986446  1635.000000   0
## 13                     max fps  0.000993 12169.000000 399
## 14                     max tps  0.032997  1638.000000 337
## 15                     max tnr  0.986446     1.000000   0
## 16                     max fnr  0.986446     0.998168   0
## 17                     max fpr  0.000993     1.000000 399
## 18                     max tpr  0.032997     1.000000 337
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: gbm
## ** Reported on validation data. **
## 
## MSE:  0.0500568
## RMSE:  0.2237338
## LogLoss:  0.1676649
## Mean Per-Class Error:  0.1296357
## AUC:  0.9554897
## AUCPR:  0.7650123
## Gini:  0.9109794
## R^2:  0.5222864
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2003 101 0.048004  =101/2104
## Yes      60 224 0.211268    =60/284
## Totals 2063 325 0.067420  =161/2388
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.231980    0.735632 202
## 2                       max f2  0.112987    0.787822 256
## 3                 max f0point5  0.509848    0.751916 123
## 4                 max accuracy  0.315646    0.937605 176
## 5                max precision  0.971834    1.000000   0
## 6                   max recall  0.003773    1.000000 389
## 7              max specificity  0.971834    1.000000   0
## 8             max absolute_mcc  0.231980    0.699278 202
## 9   max min_per_class_accuracy  0.096959    0.891160 267
## 10 max mean_per_class_accuracy  0.084637    0.895528 275
## 11                     max tns  0.971834 2104.000000   0
## 12                     max fns  0.971834  283.000000   0
## 13                     max fps  0.001067 2104.000000 399
## 14                     max tps  0.003773  284.000000 389
## 15                     max tnr  0.971834    1.000000   0
## 16                     max fnr  0.971834    0.996479   0
## 17                     max fpr  0.001067    1.000000 399
## 18                     max tpr  0.003773    1.000000 389
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: gbm
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05264287
## RMSE:  0.2294403
## LogLoss:  0.1755659
## Mean Per-Class Error:  0.1362506
## AUC:  0.9506946
## AUCPR:  0.7351852
## Gini:  0.9013892
## R^2:  0.4965349
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error         Rate
## No     11416  753 0.061879   =753/12169
## Yes      345 1293 0.210623    =345/1638
## Totals 11761 2046 0.079525  =1098/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.194276     0.701954 245
## 2                       max f2  0.121130     0.779974 277
## 3                 max f0point5  0.537980     0.723443 136
## 4                 max accuracy  0.457335     0.929746 160
## 5                max precision  0.987549     1.000000   0
## 6                   max recall  0.002288     1.000000 395
## 7              max specificity  0.987549     1.000000   0
## 8             max absolute_mcc  0.194276     0.662128 245
## 9   max min_per_class_accuracy  0.091993     0.887337 292
## 10 max mean_per_class_accuracy  0.088803     0.888101 294
## 11                     max tns  0.987549 12169.000000   0
## 12                     max fns  0.987549  1636.000000   0
## 13                     max fps  0.000742 12169.000000 399
## 14                     max tps  0.002288  1638.000000 395
## 15                     max tnr  0.987549     1.000000   0
## 16                     max fnr  0.987549     0.998779   0
## 17                     max fpr  0.000742     1.000000 399
## 18                     max tpr  0.002288     1.000000 395
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                               mean           sd  cv_1_valid cv_2_valid
## accuracy                0.92634124 0.0058955573   0.9301231   0.929399
## auc                     0.95055467 0.0053486945   0.9596708  0.9498743
## err                     0.07365879 0.0058955573   0.0698769 0.07060102
## err_count                    203.4    16.257305       193.0      195.0
## f0point5                0.68391705   0.02991979  0.72422683  0.6791641
## f1                       0.7059194  0.025415042   0.7443709  0.6938776
## f2                       0.7297664  0.025698777  0.76566756 0.70924264
## lift_top_group            7.292422   0.57823396   7.1242065  7.7114935
## logloss                 0.17556679  0.006108442   0.1722436 0.16717628
## max_per_class_error      0.2531705  0.029838206  0.21944444  0.2801303
## mcc                     0.66556454  0.026862245   0.7050183 0.65457976
## mean_per_class_accuracy  0.8485961   0.01391779   0.8665475 0.83773524
## mean_per_class_error    0.15140389   0.01391779  0.13345245 0.16226473
## mse                     0.05264312 0.0024623007 0.051882558 0.04987479
## pr_auc                  0.73401904  0.035947163   0.7964472 0.72957194
## precision                0.6701556  0.033995394   0.7113924   0.669697
## r2                      0.49547786    0.0311478    0.542287  0.4951777
## recall                   0.7468295  0.029838206  0.78055555 0.71986973
## rmse                    0.22939128  0.005334302  0.22777744 0.22332664
## specificity              0.9503627 0.0074749193  0.95253956  0.9556008
##                          cv_3_valid  cv_4_valid  cv_5_valid
## accuracy                  0.9159725   0.9290112   0.9272003
## auc                      0.94963557   0.9458547  0.94773793
## err                      0.08402753 0.070988774  0.07279971
## err_count                     232.0       196.0       201.0
## f0point5                 0.64035547   0.6892718   0.6865672
## f1                       0.67867035    0.716763   0.6959153
## f2                       0.72186214   0.7465382  0.70552146
## lift_top_group            7.8885713   7.3268466   6.4109907
## logloss                  0.18324228  0.17697719  0.17819464
## max_per_class_error      0.24615385  0.23219815   0.2879257
## mcc                       0.6350696  0.67834747   0.6548075
## mean_per_class_accuracy   0.8457244   0.8590855   0.8338879
## mean_per_class_error     0.15427561   0.1409145  0.16611215
## mse                     0.056447804 0.051640376 0.053370077
## pr_auc                   0.71895355   0.7197691   0.7053535
## precision                 0.6171285   0.6720867   0.6804734
## r2                       0.45647538  0.50009674   0.4833524
## recall                   0.75384617   0.7678019   0.7120743
## rmse                     0.23758747  0.22724518  0.23101965
## specificity              0.93760264   0.9503692   0.9557014</code></pre>
<pre class="r"><code>predictions &lt;- h2o.predict(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>typeof(predictions)</code></pre>
<pre><code>## [1] &quot;environment&quot;</code></pre>
<pre class="r"><code>predictions_tbl_2 &lt;- predictions %&gt;% as_tibble()


################### end ######################</code></pre>
<p>When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag) from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You’ll learn that all of these things and more can be customized in each R code block.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
