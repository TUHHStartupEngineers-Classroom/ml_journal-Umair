<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />



<meta name="date" content="2020-01-06" />

<title>03 Automated Machine Learning with H20</title>

<script src="site_libs/header-attrs-2.8/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MyLabJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Index</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Journal
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_ml_fund.html">01 Machine Learning Fundamentals</a>
    </li>
    <li>
      <a href="02_ml_sup.html">02 Supervised ML</a>
    </li>
    <li>
      <a href="03_ml_aut.html">03 Automated Machine Learning with H20</a>
    </li>
    <li>
      <a href="04_perf_meas.html">04 Performance Measures</a>
    </li>
    <li>
      <a href="05_lime.html">05 LIME</a>
    </li>
    <li>
      <a href="06_dl.html">06 Deep Learning</a>
    </li>
  </ul>
</li>
<li>
  <a href="07_class_notes.html">Class notes</a>
</li>
<li>
  <a href="08_links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">03 Automated Machine Learning with H20</h1>
<h4 class="date">2020-01-06</h4>

</div>


<p><strong>IMPORTANT:</strong> You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.</p>
<p>This is an <code>.Rmd</code> file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.</p>
<div id="my-first-post" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> My first post</h1>
<p>Last compiled: 2021-06-03</p>
<p>Notice that whatever you define as a top level header, automatically gets put into the table of contents bar on the left.</p>
<div id="second-level-header" class="section level2" number="1.1">
<h2 number="1.1"><span class="header-section-number">1.1</span> Second level header</h2>
<p>You can add more headers by adding more hashtags. These won’t be put into the table of contents</p>
<div id="third-level-header" class="section level3" number="1.1.1">
<h3 number="1.1.1"><span class="header-section-number">1.1.1</span> third level header</h3>
<p>Here’s an even lower level header</p>
</div>
</div>
</div>
<div id="my-second-post-note-the-order" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> My second post (note the order)</h1>
<p>Last compiled: 2021-06-03</p>
<p>I’m writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom</p>
</div>
<div id="adding-r-stuff" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Adding R stuff</h1>
<p>So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the same place.</p>
<p>So, let’s say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation = 1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:</p>
<pre class="r"><code>library(tidyverse)
library(readxl)
library(h2o)
library(rsample)
library(recipes)





############ STEP # 1 ############################




product_backorder_tbl          &lt;- read_csv(&quot;product_backorders.csv&quot;)

set.seed(seed = 1113)
split_obj                       &lt;- rsample::initial_split(product_backorder_tbl, prop = 0.85)
train_readable_tbl              &lt;- training(split_obj)
test_readable_tbl               &lt;- testing(split_obj)

recipe_obj &lt;- recipe(went_on_backorder ~., data = train_readable_tbl) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  prep()

train_tbl &lt;- bake(recipe_obj, new_data = train_readable_tbl)
test_tbl  &lt;- bake(recipe_obj, new_data = test_readable_tbl)















############ STEP # 2 ############################




# Modeling
h2o.init()</code></pre>
<pre><code>##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         4 days 1 hours 
##     H2O cluster timezone:       +01:00 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.32.1.3 
##     H2O cluster version age:    14 days, 20 hours and 13 minutes  
##     H2O cluster name:           H2O_started_from_R_M_Umair_Chaudhry_wae888 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   1.31 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4 
##     R Version:                  R version 4.1.0 (2021-05-18)</code></pre>
<pre class="r"><code>split_h2o &lt;- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>train_h2o &lt;- split_h2o[[1]]
valid_h2o &lt;- split_h2o[[2]]
test_h2o  &lt;- as.h2o(test_tbl)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>y &lt;- &quot;went_on_backorder&quot;
x &lt;- setdiff(names(train_h2o), y)






############ STEP # 3 ############################




?h2o.automl

automl_models_h2o &lt;- h2o.automl(
  x = x,
  y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = 300,
  nfolds            = 5 
)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
## 14:13:59.745: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.
## 14:13:59.748: AutoML: XGBoost is not available; skipping it.
  |                                                                            
  |====                                                                  |   6%
  |                                                                            
  |======                                                                |   8%
  |                                                                            
  |======                                                                |   9%
  |                                                                            
  |=======                                                               |  10%
  |                                                                            
  |========                                                              |  12%
  |                                                                            
  |=========                                                             |  13%
  |                                                                            
  |===========                                                           |  15%
  |                                                                            
  |===========                                                           |  16%
  |                                                                            
  |=============                                                         |  19%
  |                                                                            
  |==============                                                        |  20%
  |                                                                            
  |=================                                                     |  24%
  |                                                                            
  |====================                                                  |  28%
  |                                                                            
  |====================                                                  |  29%
  |                                                                            
  |=======================                                               |  33%
  |                                                                            
  |=========================                                             |  36%
  |                                                                            
  |==========================                                            |  37%
  |                                                                            
  |=============================                                         |  41%
  |                                                                            
  |=============================                                         |  42%
  |                                                                            
  |==============================                                        |  43%
  |                                                                            
  |=================================                                     |  48%
  |                                                                            
  |==================================                                    |  48%
  |                                                                            
  |===================================                                   |  50%
  |                                                                            
  |====================================                                  |  51%
  |                                                                            
  |======================================                                |  54%
  |                                                                            
  |======================================                                |  55%
  |                                                                            
  |========================================                              |  57%
  |                                                                            
  |=========================================                             |  58%
  |                                                                            
  |==========================================                            |  60%
  |                                                                            
  |===========================================                           |  62%
  |                                                                            
  |============================================                          |  62%
  |                                                                            
  |=================================================                     |  70%
  |                                                                            
  |====================================================                  |  75%
  |                                                                            
  |========================================================              |  80%
  |                                                                            
  |=========================================================             |  81%
  |                                                                            
  |===============================================================       |  90%
  |                                                                            
  |=================================================================     |  94%
  |                                                                            
  |==================================================================    |  94%
  |                                                                            
  |====================================================================  |  97%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>################Step 4 View the leaderboard##############


typeof(automl_models_h2o)</code></pre>
<pre><code>## [1] &quot;S4&quot;</code></pre>
<pre class="r"><code>slotNames(automl_models_h2o)</code></pre>
<pre><code>## [1] &quot;project_name&quot;   &quot;leader&quot;         &quot;leaderboard&quot;    &quot;event_log&quot;     
## [5] &quot;modeling_steps&quot; &quot;training_info&quot;</code></pre>
<pre class="r"><code>automl_models_h2o@leaderboard</code></pre>
<pre><code>##                                              model_id       auc   logloss
## 1 StackedEnsemble_BestOfFamily_AutoML_20210603_141359 0.9522523 0.1725173
## 2    StackedEnsemble_AllModels_AutoML_20210603_141359 0.9509584 0.1742625
## 3                        GBM_4_AutoML_20210603_141359 0.9501102 0.1791247
## 4                        GBM_3_AutoML_20210603_141359 0.9481057 0.1848506
## 5                        GBM_2_AutoML_20210603_141359 0.9455023 0.1841580
## 6                        GBM_5_AutoML_20210603_141359 0.9453300 0.1890180
##       aucpr mean_per_class_error      rmse        mse
## 1 0.7481674            0.1622079 0.2281930 0.05207203
## 2 0.7428377            0.1472290 0.2298464 0.05282937
## 3 0.7451141            0.1645182 0.2310191 0.05336983
## 4 0.7307435            0.1452552 0.2332528 0.05440686
## 5 0.7248317            0.1480246 0.2329968 0.05428749
## 6 0.7117867            0.1658492 0.2373259 0.05632360
## 
## [22 rows x 7 columns]</code></pre>
<pre class="r"><code>automl_models_h2o@leader</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: stackedensemble
## Model ID:  StackedEnsemble_BestOfFamily_AutoML_20210603_141359 
## Number of Base Models: 5
## 
## Base Models (count by algorithm type):
## 
## deeplearning          drf          gbm          glm 
##            1            2            1            1 
## 
## Metalearner:
## 
## Metalearner algorithm: glm
## Metalearner cross-validation fold assignment:
##   Fold assignment scheme: AUTO
##   Number of folds: 5
##   Fold column: NULL
## Metalearner hyperparameters: 
## 
## 
## H2OBinomialMetrics: stackedensemble
## ** Reported on training data. **
## 
## MSE:  0.02351256
## RMSE:  0.153338
## LogLoss:  0.08976508
## Mean Per-Class Error:  0.06311984
## AUC:  0.9916933
## AUCPR:  0.9542109
## Gini:  0.9833866
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     8662  163 0.018470   =163/8825
## Yes     129 1068 0.107769   =129/1197
## Totals 8791 1231 0.029136  =292/10022
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.394852    0.879736 182
## 2                       max f2  0.303715    0.902475 208
## 3                 max f0point5  0.546284    0.910878 142
## 4                 max accuracy  0.532946    0.971662 145
## 5                max precision  0.999935    1.000000   0
## 6                   max recall  0.020948    1.000000 349
## 7              max specificity  0.999935    1.000000   0
## 8             max absolute_mcc  0.394852    0.863274 182
## 9   max min_per_class_accuracy  0.225338    0.952381 234
## 10 max mean_per_class_accuracy  0.205434    0.952634 241
## 11                     max tns  0.999935 8825.000000   0
## 12                     max fns  0.999935 1196.000000   0
## 13                     max fps  0.000055 8825.000000 399
## 14                     max tps  0.020948 1197.000000 349
## 15                     max tnr  0.999935    1.000000   0
## 16                     max fnr  0.999935    0.999165   0
## 17                     max fpr  0.000055    1.000000 399
## 18                     max tpr  0.020948    1.000000 349
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: stackedensemble
## ** Reported on validation data. **
## 
## MSE:  0.0483163
## RMSE:  0.2198097
## LogLoss:  0.1630459
## Mean Per-Class Error:  0.1504813
## AUC:  0.9542329
## AUCPR:  0.7751411
## Gini:  0.9084658
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2019  85 0.040399   =85/2104
## Yes      74 210 0.260563    =74/284
## Totals 2093 295 0.066583  =159/2388
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.358579    0.725389 173
## 2                       max f2  0.169896    0.802943 237
## 3                 max f0point5  0.693159    0.751096  87
## 4                 max accuracy  0.401531    0.933417 160
## 5                max precision  0.983386    1.000000   0
## 6                   max recall  0.005652    1.000000 382
## 7              max specificity  0.983386    1.000000   0
## 8             max absolute_mcc  0.218726    0.687719 217
## 9   max min_per_class_accuracy  0.130370    0.894487 258
## 10 max mean_per_class_accuracy  0.158521    0.900746 243
## 11                     max tns  0.983386 2104.000000   0
## 12                     max fns  0.983386  283.000000   0
## 13                     max fps  0.000059 2104.000000 399
## 14                     max tps  0.005652  284.000000 382
## 15                     max tnr  0.983386    1.000000   0
## 16                     max fnr  0.983386    0.996479   0
## 17                     max fpr  0.000059    1.000000 399
## 18                     max tpr  0.005652    1.000000 382
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: stackedensemble
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05060219
## RMSE:  0.2249493
## LogLoss:  0.1704229
## Mean Per-Class Error:  0.1513259
## AUC:  0.952365
## AUCPR:  0.7451921
## Gini:  0.9047299
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error         Rate
## No     11584  585 0.048073   =585/12169
## Yes      417 1221 0.254579    =417/1638
## Totals 12001 1806 0.072572  =1002/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.338783     0.709059 202
## 2                       max f2  0.143296     0.774948 272
## 3                 max f0point5  0.575394     0.725209 129
## 4                 max accuracy  0.470976     0.930905 160
## 5                max precision  0.987668     1.000000   0
## 6                   max recall  0.000047     1.000000 399
## 7              max specificity  0.987668     1.000000   0
## 8             max absolute_mcc  0.338783     0.668754 202
## 9   max min_per_class_accuracy  0.113166     0.883639 288
## 10 max mean_per_class_accuracy  0.082418     0.887416 307
## 11                     max tns  0.987668 12169.000000   0
## 12                     max fns  0.987668  1635.000000   0
## 13                     max fps  0.000047 12169.000000 399
## 14                     max tps  0.000047  1638.000000 399
## 15                     max tnr  0.987668     1.000000   0
## 16                     max fnr  0.987668     0.998168   0
## 17                     max fpr  0.000047     1.000000 399
## 18                     max tpr  0.000047     1.000000 399
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre>
<pre class="r"><code>extract_h2o_model_name_by_position &lt;- function(h2o_leaderboard, n = 1, verbose = T) {
  
  model_name &lt;- h2o_leaderboard %&gt;%
    as_tibble() %&gt;%
    slice(n) %&gt;%
    pull(model_id)
  
  if (verbose) message(model_name)
  
  return(model_name)
  
}


automl_models_h2o@leaderboard %&gt;% 
  extract_h2o_model_name_by_position(14) %&gt;% 
  h2o.getModel() %&gt;%






################ Saving &amp; Loading H2O models Step#5 ###############


  h2o.saveModel(path = &quot;04_Modeling/h20_models/challenge&quot;)</code></pre>
<pre><code>## [1] &quot;C:\\THIS PC\\TUHH S-I\\S - IV\\ML\\Challenge\\Challange_H2O\\Challenge_H2O_2\\Challenge\\Challenge_2nd_Actual\\04_Modeling\\h20_models\\challenge\\DRF_1_AutoML_20210603_141359&quot;</code></pre>
<pre class="r"><code>h2o.loadModel(&quot;04_Modeling/h20_models/challenge/GBM_grid__1_AutoML_20210531_150000_model_3&quot;)</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: gbm
## Model ID:  GBM_grid__1_AutoML_20210531_150000_model_3 
## Model Summary: 
##   number_of_trees number_of_internal_trees model_size_in_bytes min_depth
## 1              68                       68              283064         0
##   max_depth mean_depth min_leaves max_leaves mean_leaves
## 1        12   11.26471          1        680   326.50000
## 
## 
## H2OBinomialMetrics: gbm
## ** Reported on training data. **
## 
## MSE:  0.01361432
## RMSE:  0.1166804
## LogLoss:  0.06477669
## Mean Per-Class Error:  0.02881662
## AUC:  0.9982883
## AUCPR:  0.9907718
## Gini:  0.9965767
## R^2:  0.8697956
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error        Rate
## No     12114   55 0.004520   =55/12169
## Yes       87 1551 0.053114    =87/1638
## Totals 12201 1606 0.010285  =142/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.409278     0.956227 185
## 2                       max f2  0.320421     0.960746 205
## 3                 max f0point5  0.554375     0.969592 154
## 4                 max accuracy  0.409278     0.989715 185
## 5                max precision  0.986446     1.000000   0
## 6                   max recall  0.032997     1.000000 337
## 7              max specificity  0.986446     1.000000   0
## 8             max absolute_mcc  0.409278     0.950460 185
## 9   max min_per_class_accuracy  0.239557     0.979853 228
## 10 max mean_per_class_accuracy  0.212380     0.980571 239
## 11                     max tns  0.986446 12169.000000   0
## 12                     max fns  0.986446  1635.000000   0
## 13                     max fps  0.000993 12169.000000 399
## 14                     max tps  0.032997  1638.000000 337
## 15                     max tnr  0.986446     1.000000   0
## 16                     max fnr  0.986446     0.998168   0
## 17                     max fpr  0.000993     1.000000 399
## 18                     max tpr  0.032997     1.000000 337
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: gbm
## ** Reported on validation data. **
## 
## MSE:  0.0500568
## RMSE:  0.2237338
## LogLoss:  0.1676649
## Mean Per-Class Error:  0.1296357
## AUC:  0.9554897
## AUCPR:  0.7650123
## Gini:  0.9109794
## R^2:  0.5222864
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2003 101 0.048004  =101/2104
## Yes      60 224 0.211268    =60/284
## Totals 2063 325 0.067420  =161/2388
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.231980    0.735632 202
## 2                       max f2  0.112987    0.787822 256
## 3                 max f0point5  0.509848    0.751916 123
## 4                 max accuracy  0.315646    0.937605 176
## 5                max precision  0.971834    1.000000   0
## 6                   max recall  0.003773    1.000000 389
## 7              max specificity  0.971834    1.000000   0
## 8             max absolute_mcc  0.231980    0.699278 202
## 9   max min_per_class_accuracy  0.096959    0.891160 267
## 10 max mean_per_class_accuracy  0.084637    0.895528 275
## 11                     max tns  0.971834 2104.000000   0
## 12                     max fns  0.971834  283.000000   0
## 13                     max fps  0.001067 2104.000000 399
## 14                     max tps  0.003773  284.000000 389
## 15                     max tnr  0.971834    1.000000   0
## 16                     max fnr  0.971834    0.996479   0
## 17                     max fpr  0.001067    1.000000 399
## 18                     max tpr  0.003773    1.000000 389
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: gbm
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05264287
## RMSE:  0.2294403
## LogLoss:  0.1755659
## Mean Per-Class Error:  0.1362506
## AUC:  0.9506946
## AUCPR:  0.7351852
## Gini:  0.9013892
## R^2:  0.4965349
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error         Rate
## No     11416  753 0.061879   =753/12169
## Yes      345 1293 0.210623    =345/1638
## Totals 11761 2046 0.079525  =1098/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.194276     0.701954 245
## 2                       max f2  0.121130     0.779974 277
## 3                 max f0point5  0.537980     0.723443 136
## 4                 max accuracy  0.457335     0.929746 160
## 5                max precision  0.987549     1.000000   0
## 6                   max recall  0.002288     1.000000 395
## 7              max specificity  0.987549     1.000000   0
## 8             max absolute_mcc  0.194276     0.662128 245
## 9   max min_per_class_accuracy  0.091993     0.887337 292
## 10 max mean_per_class_accuracy  0.088803     0.888101 294
## 11                     max tns  0.987549 12169.000000   0
## 12                     max fns  0.987549  1636.000000   0
## 13                     max fps  0.000742 12169.000000 399
## 14                     max tps  0.002288  1638.000000 395
## 15                     max tnr  0.987549     1.000000   0
## 16                     max fnr  0.987549     0.998779   0
## 17                     max fpr  0.000742     1.000000 399
## 18                     max tpr  0.002288     1.000000 395
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                               mean           sd  cv_1_valid cv_2_valid
## accuracy                0.92634124 0.0058955573   0.9301231   0.929399
## auc                     0.95055467 0.0053486945   0.9596708  0.9498743
## err                     0.07365879 0.0058955573   0.0698769 0.07060102
## err_count                    203.4    16.257305       193.0      195.0
## f0point5                0.68391705   0.02991979  0.72422683  0.6791641
## f1                       0.7059194  0.025415042   0.7443709  0.6938776
## f2                       0.7297664  0.025698777  0.76566756 0.70924264
## lift_top_group            7.292422   0.57823396   7.1242065  7.7114935
## logloss                 0.17556679  0.006108442   0.1722436 0.16717628
## max_per_class_error      0.2531705  0.029838206  0.21944444  0.2801303
## mcc                     0.66556454  0.026862245   0.7050183 0.65457976
## mean_per_class_accuracy  0.8485961   0.01391779   0.8665475 0.83773524
## mean_per_class_error    0.15140389   0.01391779  0.13345245 0.16226473
## mse                     0.05264312 0.0024623007 0.051882558 0.04987479
## pr_auc                  0.73401904  0.035947163   0.7964472 0.72957194
## precision                0.6701556  0.033995394   0.7113924   0.669697
## r2                      0.49547786    0.0311478    0.542287  0.4951777
## recall                   0.7468295  0.029838206  0.78055555 0.71986973
## rmse                    0.22939128  0.005334302  0.22777744 0.22332664
## specificity              0.9503627 0.0074749193  0.95253956  0.9556008
##                          cv_3_valid  cv_4_valid  cv_5_valid
## accuracy                  0.9159725   0.9290112   0.9272003
## auc                      0.94963557   0.9458547  0.94773793
## err                      0.08402753 0.070988774  0.07279971
## err_count                     232.0       196.0       201.0
## f0point5                 0.64035547   0.6892718   0.6865672
## f1                       0.67867035    0.716763   0.6959153
## f2                       0.72186214   0.7465382  0.70552146
## lift_top_group            7.8885713   7.3268466   6.4109907
## logloss                  0.18324228  0.17697719  0.17819464
## max_per_class_error      0.24615385  0.23219815   0.2879257
## mcc                       0.6350696  0.67834747   0.6548075
## mean_per_class_accuracy   0.8457244   0.8590855   0.8338879
## mean_per_class_error     0.15427561   0.1409145  0.16611215
## mse                     0.056447804 0.051640376 0.053370077
## pr_auc                   0.71895355   0.7197691   0.7053535
## precision                 0.6171285   0.6720867   0.6804734
## r2                       0.45647538  0.50009674   0.4833524
## recall                   0.75384617   0.7678019   0.7120743
## rmse                     0.23758747  0.22724518  0.23101965
## specificity              0.93760264   0.9503692   0.9557014</code></pre>
<pre class="r"><code>############### Step 5 Predicting using Leader Model#####################


stacked_ensemble_h2o &lt;- h2o.loadModel(&quot;04_Modeling/h20_models/challenge/GBM_grid__1_AutoML_20210531_150000_model_3&quot;)
stacked_ensemble_h2o</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: gbm
## Model ID:  GBM_grid__1_AutoML_20210531_150000_model_3 
## Model Summary: 
##   number_of_trees number_of_internal_trees model_size_in_bytes min_depth
## 1              68                       68              283064         0
##   max_depth mean_depth min_leaves max_leaves mean_leaves
## 1        12   11.26471          1        680   326.50000
## 
## 
## H2OBinomialMetrics: gbm
## ** Reported on training data. **
## 
## MSE:  0.01361432
## RMSE:  0.1166804
## LogLoss:  0.06477669
## Mean Per-Class Error:  0.02881662
## AUC:  0.9982883
## AUCPR:  0.9907718
## Gini:  0.9965767
## R^2:  0.8697956
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error        Rate
## No     12114   55 0.004520   =55/12169
## Yes       87 1551 0.053114    =87/1638
## Totals 12201 1606 0.010285  =142/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.409278     0.956227 185
## 2                       max f2  0.320421     0.960746 205
## 3                 max f0point5  0.554375     0.969592 154
## 4                 max accuracy  0.409278     0.989715 185
## 5                max precision  0.986446     1.000000   0
## 6                   max recall  0.032997     1.000000 337
## 7              max specificity  0.986446     1.000000   0
## 8             max absolute_mcc  0.409278     0.950460 185
## 9   max min_per_class_accuracy  0.239557     0.979853 228
## 10 max mean_per_class_accuracy  0.212380     0.980571 239
## 11                     max tns  0.986446 12169.000000   0
## 12                     max fns  0.986446  1635.000000   0
## 13                     max fps  0.000993 12169.000000 399
## 14                     max tps  0.032997  1638.000000 337
## 15                     max tnr  0.986446     1.000000   0
## 16                     max fnr  0.986446     0.998168   0
## 17                     max fpr  0.000993     1.000000 399
## 18                     max tpr  0.032997     1.000000 337
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: gbm
## ** Reported on validation data. **
## 
## MSE:  0.0500568
## RMSE:  0.2237338
## LogLoss:  0.1676649
## Mean Per-Class Error:  0.1296357
## AUC:  0.9554897
## AUCPR:  0.7650123
## Gini:  0.9109794
## R^2:  0.5222864
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2003 101 0.048004  =101/2104
## Yes      60 224 0.211268    =60/284
## Totals 2063 325 0.067420  =161/2388
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.231980    0.735632 202
## 2                       max f2  0.112987    0.787822 256
## 3                 max f0point5  0.509848    0.751916 123
## 4                 max accuracy  0.315646    0.937605 176
## 5                max precision  0.971834    1.000000   0
## 6                   max recall  0.003773    1.000000 389
## 7              max specificity  0.971834    1.000000   0
## 8             max absolute_mcc  0.231980    0.699278 202
## 9   max min_per_class_accuracy  0.096959    0.891160 267
## 10 max mean_per_class_accuracy  0.084637    0.895528 275
## 11                     max tns  0.971834 2104.000000   0
## 12                     max fns  0.971834  283.000000   0
## 13                     max fps  0.001067 2104.000000 399
## 14                     max tps  0.003773  284.000000 389
## 15                     max tnr  0.971834    1.000000   0
## 16                     max fnr  0.971834    0.996479   0
## 17                     max fpr  0.001067    1.000000 399
## 18                     max tpr  0.003773    1.000000 389
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: gbm
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05264287
## RMSE:  0.2294403
## LogLoss:  0.1755659
## Mean Per-Class Error:  0.1362506
## AUC:  0.9506946
## AUCPR:  0.7351852
## Gini:  0.9013892
## R^2:  0.4965349
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           No  Yes    Error         Rate
## No     11416  753 0.061879   =753/12169
## Yes      345 1293 0.210623    =345/1638
## Totals 11761 2046 0.079525  =1098/13807
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.194276     0.701954 245
## 2                       max f2  0.121130     0.779974 277
## 3                 max f0point5  0.537980     0.723443 136
## 4                 max accuracy  0.457335     0.929746 160
## 5                max precision  0.987549     1.000000   0
## 6                   max recall  0.002288     1.000000 395
## 7              max specificity  0.987549     1.000000   0
## 8             max absolute_mcc  0.194276     0.662128 245
## 9   max min_per_class_accuracy  0.091993     0.887337 292
## 10 max mean_per_class_accuracy  0.088803     0.888101 294
## 11                     max tns  0.987549 12169.000000   0
## 12                     max fns  0.987549  1636.000000   0
## 13                     max fps  0.000742 12169.000000 399
## 14                     max tps  0.002288  1638.000000 395
## 15                     max tnr  0.987549     1.000000   0
## 16                     max fnr  0.987549     0.998779   0
## 17                     max fpr  0.000742     1.000000 399
## 18                     max tpr  0.002288     1.000000 395
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                               mean           sd  cv_1_valid cv_2_valid
## accuracy                0.92634124 0.0058955573   0.9301231   0.929399
## auc                     0.95055467 0.0053486945   0.9596708  0.9498743
## err                     0.07365879 0.0058955573   0.0698769 0.07060102
## err_count                    203.4    16.257305       193.0      195.0
## f0point5                0.68391705   0.02991979  0.72422683  0.6791641
## f1                       0.7059194  0.025415042   0.7443709  0.6938776
## f2                       0.7297664  0.025698777  0.76566756 0.70924264
## lift_top_group            7.292422   0.57823396   7.1242065  7.7114935
## logloss                 0.17556679  0.006108442   0.1722436 0.16717628
## max_per_class_error      0.2531705  0.029838206  0.21944444  0.2801303
## mcc                     0.66556454  0.026862245   0.7050183 0.65457976
## mean_per_class_accuracy  0.8485961   0.01391779   0.8665475 0.83773524
## mean_per_class_error    0.15140389   0.01391779  0.13345245 0.16226473
## mse                     0.05264312 0.0024623007 0.051882558 0.04987479
## pr_auc                  0.73401904  0.035947163   0.7964472 0.72957194
## precision                0.6701556  0.033995394   0.7113924   0.669697
## r2                      0.49547786    0.0311478    0.542287  0.4951777
## recall                   0.7468295  0.029838206  0.78055555 0.71986973
## rmse                    0.22939128  0.005334302  0.22777744 0.22332664
## specificity              0.9503627 0.0074749193  0.95253956  0.9556008
##                          cv_3_valid  cv_4_valid  cv_5_valid
## accuracy                  0.9159725   0.9290112   0.9272003
## auc                      0.94963557   0.9458547  0.94773793
## err                      0.08402753 0.070988774  0.07279971
## err_count                     232.0       196.0       201.0
## f0point5                 0.64035547   0.6892718   0.6865672
## f1                       0.67867035    0.716763   0.6959153
## f2                       0.72186214   0.7465382  0.70552146
## lift_top_group            7.8885713   7.3268466   6.4109907
## logloss                  0.18324228  0.17697719  0.17819464
## max_per_class_error      0.24615385  0.23219815   0.2879257
## mcc                       0.6350696  0.67834747   0.6548075
## mean_per_class_accuracy   0.8457244   0.8590855   0.8338879
## mean_per_class_error     0.15427561   0.1409145  0.16611215
## mse                     0.056447804 0.051640376 0.053370077
## pr_auc                   0.71895355   0.7197691   0.7053535
## precision                 0.6171285   0.6720867   0.6804734
## r2                       0.45647538  0.50009674   0.4833524
## recall                   0.75384617   0.7678019   0.7120743
## rmse                     0.23758747  0.22724518  0.23101965
## specificity              0.93760264   0.9503692   0.9557014</code></pre>
<pre class="r"><code>predictions &lt;- h2o.predict(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>typeof(predictions)</code></pre>
<pre><code>## [1] &quot;environment&quot;</code></pre>
<pre class="r"><code>predictions_tbl_2 &lt;- predictions %&gt;% as_tibble()
glimpse(predictions_tbl_2)</code></pre>
<pre><code>## Rows: 2,858
## Columns: 3
## $ predict &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, No, Yes, Yes,~
## $ No      &lt;dbl&gt; 0.3595786, 0.3293842, 0.2681036, 0.7050207, 0.1180731, 0.60036~
## $ Yes     &lt;dbl&gt; 0.64042142, 0.67061579, 0.73189635, 0.29497931, 0.88192689, 0.~</code></pre>
<pre class="r"><code>################### end ######################</code></pre>
<p>When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag) from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You’ll learn that all of these things and more can be customized in each R code block.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
